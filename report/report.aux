\relax 
\citation{nair2015}
\citation{impala2018}
\citation{apex2018}
\citation{chen2018}
\citation{dgc2018}
\citation{qsgd2017}
\citation{gpipe2019}
\citation{pipedream2019}
\citation{megatron2019}
\citation{zero2020}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Distributed Reinforcement Learning}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Communication-Efficient Distributed Training}{1}{}\protected@file@percent }
\citation{lim2020}
\citation{feng2023}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-C}}Pipeline Parallelism for Large Models}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-D}}Resource-Constrained Environments}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}Problem Statement}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Communication Overhead Analysis}{2}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Communication Overhead Comparison}}{2}{}\protected@file@percent }
\newlabel{tab:data_transfer}{{I}{2}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Method}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-A}}Experimental Setup}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-B}}Network Architecture and Partitioning}{2}{}\protected@file@percent }
\citation{dgc2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-C}}Gradient Accumulation with Percentile-Based Sparsification}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {V}Evaluation Results}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Training performance comparison. EMA-smoothed episodic returns show 90th percentile sparsification converges toward baseline performance. The dashed vertical line indicates warm start completion at 30,000 steps.}}{3}{}\protected@file@percent }
\newlabel{fig:returns}{{1}{3}{}{}{}}
\bibcite{nair2015}{1}
\bibcite{impala2018}{2}
\bibcite{apex2018}{3}
\bibcite{chen2018}{4}
\bibcite{dgc2018}{5}
\bibcite{qsgd2017}{6}
\bibcite{gpipe2019}{7}
\bibcite{pipedream2019}{8}
\bibcite{megatron2019}{9}
\bibcite{zero2020}{10}
\bibcite{lim2020}{11}
\bibcite{feng2023}{12}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Cumulative network transfer comparison. Gradient accumulation with 90th percentile threshold reduces data transfer by 37.5\%, saving 53.42 GB over 400,000 training steps.}}{4}{}\protected@file@percent }
\newlabel{fig:network}{{2}{4}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Future Work (CS298 Plan)}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{4}{}\protected@file@percent }
\gdef \@abspage@last{4}
